{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
    "</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test Uniform, Default and Xavier Uniform Initialization on MNIST dataset with tanh activation</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Objective for this Notebook<h3>    \n",
    "<h5> 1. Define Several Neural Network, Criterion function, Optimizer</h5>\n",
    "<h5> 2. Test Uniform, Default and Xavier Initialization </h5>     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "In this lab, you will test PyTroch Default Initialization, Xavier Initialization and Uniform Initialization on the MNIST dataset. \n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#Model\">Neural Network Module and Training Function</a></li>\n",
    "    <li><a href=\"#Make\">Make Some Data</a></li>\n",
    "    <li><a href=\"#Cost\">Define Several Neural Network, Criterion function, Optimizer</a></li>\n",
    "    <li><a href=\"#Train\">Test Uniform, Default and Xavier Initialization</a></li>\n",
    "    <li><a href=\"#Result\">Analyze Results</a></li>\n",
    "</ul>\n",
    "\n",
    "<p>Estimated Time Needed: <strong>25 min</strong></p>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparation</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the following libraries:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fca2eac2fd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the libraries we need to use in this lab\n",
    "\n",
    "# Using the following line code to install the torchvision library\n",
    "# !conda install -y torchvision\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Model\">Neural Network Module and Training Function</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network module or class with Xavier Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network with Xavier initialization\n",
    "\n",
    "class Net_Xavier(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, Layers):\n",
    "        super(Net_Xavier, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "\n",
    "        for input_size, output_size in zip(Layers, Layers[1:]):\n",
    "            linear = nn.Linear(input_size, output_size)\n",
    "            torch.nn.init.xavier_uniform_(linear.weight)\n",
    "            self.hidden.append(linear)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        L = len(self.hidden)\n",
    "        for (l, linear_transform) in zip(range(L), self.hidden):\n",
    "            if l < L - 1:\n",
    "                x = torch.tanh(linear_transform(x))\n",
    "            else:\n",
    "                x = linear_transform(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network module with Uniform Initialization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network with Uniform initialization\n",
    "\n",
    "class Net_Uniform(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, Layers):\n",
    "        super(Net_Uniform, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "\n",
    "        for input_size, output_size in zip(Layers, Layers[1:]):\n",
    "            linear = nn.Linear(input_size, output_size)\n",
    "            linear.weight.data.uniform_(0, 1)\n",
    "            self.hidden.append(linear)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        L = len(self.hidden)\n",
    "        for (l, linear_transform) in zip(range(L), self.hidden):\n",
    "            if l < L - 1:\n",
    "                x = torch.tanh(linear_transform(x))\n",
    "            else:\n",
    "                x = linear_transform(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network module with PyTroch Default Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network with Default initialization\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, Layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "\n",
    "        for input_size, output_size in zip(Layers, Layers[1:]):\n",
    "            linear = nn.Linear(input_size, output_size)\n",
    "            self.hidden.append(linear)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        L = len(self.hidden)\n",
    "        for (l, linear_transform) in zip(range(L), self.hidden):\n",
    "            if l < L - 1:\n",
    "                x = torch.tanh(linear_transform(x))\n",
    "            else:\n",
    "                x = linear_transform(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to train the model, in this case the function returns a Python dictionary to store the training loss and accuracy on the validation data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to Train the model\n",
    "\n",
    "def train(model, criterion, train_loader, validation_loader, optimizer, epochs = 100):\n",
    "    i = 0\n",
    "    loss_accuracy = {'training_loss':[], 'validation_accuracy':[]}  \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i,(x, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_accuracy['training_loss'].append(loss.data.item())\n",
    "            \n",
    "        correct = 0\n",
    "        for x, y in validation_loader:\n",
    "            yhat = model(x.view(-1, 28 * 28))\n",
    "            _, label = torch.max(yhat, 1)\n",
    "            correct += (label==y).sum().item()\n",
    "        accuracy = 100 * (correct / len(validation_dataset))\n",
    "        loss_accuracy['validation_accuracy'].append(accuracy)\n",
    "        \n",
    "    return loss_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Makeup_Data\">Make Some Data</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training dataset by setting the parameters <code>train </code> to <code>True</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train dataset\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the testing dataset by setting the parameters <code>train</code> to <code>False</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the validation dataset\n",
    "\n",
    "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training-data loader and the validation-data loader object \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataloader for both train dataset and validation dataset\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Cost\">Define Neural Network, Criterion function, Optimizer and Train the Model</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the criterion function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define criterion function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model with 100 hidden layers  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "\n",
    "input_dim = 28 * 28\n",
    "output_dim = 10\n",
    "layers = [input_dim, 100, 10, 100, 10, 100, output_dim]\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Train\">Test PyTorch Default Initialization, Xavier Initialization, Uniform Initialization</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network using PyTorch Default Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with default initialization\n",
    "\n",
    "model = Net(layers)\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "training_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network using Xavier Initialization function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with Xavier initialization\n",
    "\n",
    "model_Xavier = Net_Xavier(layers)\n",
    "optimizer = torch.optim.SGD(model_Xavier.parameters(), lr=learning_rate)\n",
    "training_results_Xavier = train(model_Xavier, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network using Uniform Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with Uniform initialization\n",
    "\n",
    "model_Uniform = Net_Uniform(layers)\n",
    "optimizer = torch.optim.SGD(model_Uniform.parameters(), lr=learning_rate)\n",
    "training_results_Uniform = train(model_Uniform, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Result\">Analyse Results</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the training loss for each initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "\n",
    "plt.plot(training_results_Xavier['training_loss'], label='Xavier')\n",
    "plt.plot(training_results['training_loss'], label='Default')\n",
    "plt.plot(training_results_Uniform['training_loss'], label='Uniform')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iteration ')  \n",
    "plt.title('training loss iterations')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare the validation loss for each model  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy\n",
    "\n",
    "plt.plot(training_results_Xavier['validation_accuracy'], label='Xavier')\n",
    "plt.plot(training_results['validation_accuracy'], label='Default')\n",
    "plt.plot(training_results_Uniform['validation_accuracy'], label='Uniform') \n",
    "plt.ylabel('validation accuracy')\n",
    "plt.xlabel('epochs')   \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_bottom\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/notebook_bottom%20.png\" width=\"750\" alt=\"PyTorch Bottom\" />\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n",
    "\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                          |\n",
    "| ----------------- | ------- | ---------- | ----------------------------------------------------------- |\n",
    "| 2020-09-23        | 2.0     | Srishti    | Migrated Lab to Markdown and added to course repo in GitLab |\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
